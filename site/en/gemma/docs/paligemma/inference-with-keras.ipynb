{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ohilgh/DIP/blob/main/site/en/gemma/docs/paligemma/inference-with-keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3MMAcssHTML"
      },
      "source": [
        "<link rel=\"stylesheet\" href=\"/site-assets/css/gemma.css\">\n",
        "<link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/css2?family=Google+Symbols:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_lX1k54KKrx"
      },
      "source": [
        "Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Gr4W9nspKGtb"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5_nIe-8gdJV"
      },
      "source": [
        "# Generate PaliGemma output with Keras\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "<td>\n",
        "<a target=\"_blank\" href=\"https://ai.google.dev/gemma/docs/paligemma/inference-with-keras\"><img src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" />View on ai.google.dev</a>\n",
        "</td>\n",
        "<td>\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemma/docs/paligemma/inference-with-keras.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "</td>\n",
        "<td>\n",
        "<a target=\"_blank\" href=\"https://github.com/google/generative-ai-docs/blob/main/site/en/gemma/docs/paligemma/inference-with-keras.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hhIuS9sEKHx"
      },
      "source": [
        "PaliGemma models have *multimodal* capabilities, allowing you to generate output using both text and image input data. You can use image data with these models to provide additional context for your requests, or use the model to  analyze the content of images. This tutorial shows you how to use PaliGemma with Keras to can analyze images and answer questions about them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JaII1xxfbfz"
      },
      "source": [
        "## What's in this notebook\n",
        "\n",
        "This notebook uses PaliGemma with Keras and shows you how to:\n",
        "\n",
        "* Install Keras and the required dependencies\n",
        "* Download `PaliGemmaCausalLM`, a pre-trained PaliGemma variant for causal visual language modeling, and use it to create a model\n",
        "* Test the model's ability to infer information about supplied images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf7AUi02fcPL"
      },
      "source": [
        "## Before you begin\n",
        "\n",
        "Before going through this notebook, you should be familiar with Python code, as well as how large language models (LLMs) are trained. You don't need to be familiar with Keras, but basic knowledge about Keras is helpful when reading through the example code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "380it9kIhzmm"
      },
      "source": [
        "## Setup\n",
        "\n",
        "The following sections explain the preliminary steps for getting a notebook to use a PaliGemma model, including model access, getting an API key, and configuring the notebook runtime."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uN0EpPJh7t5"
      },
      "source": [
        "### Get access to PaliGemma\n",
        "\n",
        "Before using PaliGemma for the first time, you must request access to the model through Kaggle by completing the following steps:\n",
        "\n",
        "1. Log in to [Kaggle](https://www.kaggle.com), or create a new Kaggle account if you don't already have one.\n",
        "1. Go to the [PaliGemma model card](https://www.kaggle.com/models/google/paligemma-2/) and click **Request Access**.\n",
        "1. Complete the consent form and accept the terms and conditions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz_pBNrWiDqe"
      },
      "source": [
        "### Configure your API key\n",
        "\n",
        "To use PaliGemma, you must provide your Kaggle username and a Kaggle API key.\n",
        "\n",
        "To generate a Kaggle API key, open your [**Settings** page in Kaggle](https://www.kaggle.com/settings) and click **Create New Token**. This triggers the download of a `kaggle.json` file containing your API credentials.\n",
        "\n",
        "Then, in Colab, select **Secrets** (ðŸ”‘) in the left pane and add your Kaggle username and Kaggle API key. Store your username under the name `KAGGLE_USERNAME` and your API key under the name `KAGGLE_KEY`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUB4JE0Hlxce"
      },
      "source": [
        "### Select the runtime\n",
        "\n",
        "To complete this tutorial, you'll need to have a Colab runtime with sufficient resources to run the PaliGemma model. In this case, you can use a T4 GPU:\n",
        "\n",
        "1. In the upper-right of the Colab window, click the **â–¾ (Additional connection options)** dropdown menu.\n",
        "1. Select **Change runtime type**.\n",
        "1. Under **Hardware accelerator**, select **T4 GPU**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIvv2Yo3lycQ"
      },
      "source": [
        "### Set environment variables\n",
        "\n",
        "Set the environment variables for `KAGGLE_USERNAME`, `KAGGLE_KEY`, and `KERAS_BACKEND`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rdgwLyZLQBkP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set up environmental variables\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get('KAGGLE_USERNAME')\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY')\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a3Q4VCLljR9"
      },
      "source": [
        "### Install Keras\n",
        "\n",
        "Run the below cell to install Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DoYMMytAaMRJ"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q keras-nlp kagglehub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2Y7BRtRgfvG"
      },
      "source": [
        "### Import dependencies and configure Keras\n",
        "\n",
        "Install the dependencies needed for this notebook and configure Keras' backend. You'll also set Keras to use `bfloat16` so that the framework uses less memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MHECpBe6LE7y"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import keras_hub\n",
        "import numpy as np\n",
        "import PIL\n",
        "import requests\n",
        "import io\n",
        "import matplotlib\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "\n",
        "keras.config.set_floatx(\"bfloat16\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list\n"
      ],
      "metadata": {
        "id": "ueex9LG6bJax",
        "outputId": "d0c76870-41ad-4d36-b126-f6e2dc5aa5cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "401 - Unauthorized - Unauthenticated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-LE2E1uiSpP"
      },
      "source": [
        "## Load the model\n",
        "\n",
        "Now that you've set everything up, you can download the pre-trained model and create some utility methods to help your model generate its responses.\n",
        "In this step, you download a model using `PaliGemmaCausalLM` from Keras Hub. This class helps you manage and run the causal visual language model structure of PaliGemma. A *causal visual language model* predicts the next token based on previous tokens. Keras Hub provides implementations of many popular [model architectures](https://keras.io/keras_hub/api/models/).\n",
        "\n",
        "\n",
        "Create the model using the `from_preset` method and print its summary. This process will take about a minute to complete."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "THjZ-rupyXHd",
        "outputId": "f092b786-f9ef-43c1-d110-be77b512f56d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-hub --upgrade\n"
      ],
      "metadata": {
        "id": "SyuH1hyS4KLo",
        "outputId": "c30cc839-8387-4e1d-ee32-9e08d7a55ab2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-hub in /usr/local/lib/python3.11/dist-packages (0.19.1)\n",
            "Requirement already satisfied: keras>=3.5 in /usr/local/lib/python3.11/dist-packages (from keras-hub) (3.8.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras-hub) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras-hub) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-hub) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from keras-hub) (2024.11.6)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras-hub) (13.9.4)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (from keras-hub) (0.3.10)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.11/dist-packages (from keras-hub) (2.18.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5->keras-hub) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=3.5->keras-hub) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5->keras-hub) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=3.5->keras-hub) (0.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras-hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras-hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras-hub) (4.67.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras-hub) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras-hub) (2.18.0)\n",
            "Requirement already satisfied: tensorflow<2.19,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-text->keras-hub) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras-hub) (0.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (4.25.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (2.18.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (0.37.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-hub) (2025.1.31)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (0.45.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_hub\n",
        "from keras_hub.models import PaliGemmaCausalLM\n"
      ],
      "metadata": {
        "id": "0I1WWYY04TW1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()  # Upload kaggle.json here\n"
      ],
      "metadata": {
        "id": "97AJIjHa4vRu",
        "outputId": "6dcb5ab4-54a4-4ba4-cc0f-bfe0a93e9bbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-11292e9a-dd23-4de7-bab0-a647ebbe336c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-11292e9a-dd23-4de7-bab0-a647ebbe336c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"ohilhosamane\",\"key\":\"a7ee21374392b04094438bd07e8df50a\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir())  # Check if kaggle.json is in the file list\n"
      ],
      "metadata": {
        "id": "LAVVp0Ve7aGH",
        "outputId": "5f882a11-13e7-49a7-d53b-634a25031989",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'drive', '.ipynb_checkpoints', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Ensure the Kaggle directory exists\n",
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "\n",
        "# Move the uploaded kaggle.json file\n",
        "shutil.move(\"/content/kaggle.json\", \"/root/.kaggle/kaggle.json\")\n",
        "\n",
        "# Set the correct permissions\n",
        "os.chmod(\"/root/.kaggle/kaggle.json\", 600)\n",
        "\n",
        "print(\"âœ… Kaggle API key successfully set!\")\n"
      ],
      "metadata": {
        "id": "E6sHfAFA44sO",
        "outputId": "39c7916a-c320-4c31-8d82-acd487d0477e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Kaggle API key successfully set!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list\n"
      ],
      "metadata": {
        "id": "ETvHCO3Q5N8Q",
        "outputId": "c8f110c1-58bf-4613-921b-5839c5cfd877",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "401 - Unauthorized - Unauthenticated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print(\"âœ… TPU detected:\", tpu.master())\n",
        "except:\n",
        "    print(\"âŒ No TPU found.\")\n"
      ],
      "metadata": {
        "id": "uFd5KEBd8K8w",
        "outputId": "1b0b5d6f-9d30-4fa1-b034-4d4f05f9d777",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ No TPU found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "    print(\"âœ… TPU activated!\")\n",
        "except:\n",
        "    print(\"âŒ TPU not available. Falling back to CPU.\")\n"
      ],
      "metadata": {
        "id": "czIcRrnH5yDY",
        "outputId": "1524d145-9fde-412e-fb6a-26cbf800dbae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ TPU not available. Falling back to CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "abNuIP8D_9At",
        "outputId": "a7d3c6cc-ceee-4b9f-d3da-9c24c0c8683f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "403 Client Error.\n\nYou don't have permission to access resource at URL: https://www.kaggle.com/models/keras/paligemma2/keras/pali_gemma2_pt_3b_224/2. The server reported the following issues: Permission denied on resource (or it may not exists).\nPlease make sure you are authenticated if you are trying to access a private resource or a resource requiring consent.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/exceptions.py\u001b[0m in \u001b[0;36mkaggle_api_raise_for_status\u001b[0;34m(response, resource_handle)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://www.kaggle.com/api/v1/models/keras/paligemma2/keras/pali_gemma2_pt_3b_224/2/download/config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKaggleApiHTTPError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_hub/src/utils/preset_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[0;34m(preset, path)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mkagglehub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkaggle_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKaggleApiHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/models.py\u001b[0m in \u001b[0;36mmodel_download\u001b[0;34m(handle, path, force_download)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloading Model: {h.to_url()} ...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mEXTRA_CONSOLE_BLOCK\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_resolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/registry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/resolver.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, handle, path, force_download)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \"\"\"\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/http_resolver.py\u001b[0m in \u001b[0;36m_resolve\u001b[0;34m(self, h, path, force_download)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mapi_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_auto_compressed_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/clients.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(self, path, out_file, resource_handle, cached_path, extract_auto_compressed_file)\u001b[0m\n\u001b[1;32m    181\u001b[0m         ) as response:\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mkaggle_api_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/exceptions.py\u001b[0m in \u001b[0;36mkaggle_api_raise_for_status\u001b[0;34m(response, resource_handle)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# Default handling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKaggleApiHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKaggleApiHTTPError\u001b[0m: 403 Client Error.\n\nYou don't have permission to access resource at URL: https://www.kaggle.com/models/keras/paligemma2/keras/pali_gemma2_pt_3b_224/2. The server reported the following issues: Permission denied on resource (or it may not exists).\nPlease make sure you are authenticated if you are trying to access a private resource or a resource requiring consent.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-45785e9a48c0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpaligemma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_hub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPaliGemmaCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_preset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"kaggle://keras/paligemma2/keras/pali_gemma2_pt_3b_224\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpaligemma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_hub/src/models/task.py\u001b[0m in \u001b[0;36mfrom_preset\u001b[0;34m(cls, preset, load_weights, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m             )\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_preset_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0mbackbone_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_backbone_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;31m# Detect the correct subclass if we need to.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_hub/src/utils/preset_utils.py\u001b[0m in \u001b[0;36mget_preset_loader\u001b[0;34m(preset)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_preset_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_file_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONFIG_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m         raise ValueError(\n\u001b[1;32m    529\u001b[0m             \u001b[0;34mf\"Preset {preset} has no {CONFIG_FILE}. Make sure the URI or \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_hub/src/utils/preset_utils.py\u001b[0m in \u001b[0;36mcheck_file_exists\u001b[0;34m(preset, path)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_file_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mget_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_hub/src/utils/preset_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[0;34m(preset, path)\u001b[0m\n\u001b[1;32m    156\u001b[0m                 )\n\u001b[1;32m    157\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 403 Client Error.\n\nYou don't have permission to access resource at URL: https://www.kaggle.com/models/keras/paligemma2/keras/pali_gemma2_pt_3b_224/2. The server reported the following issues: Permission denied on resource (or it may not exists).\nPlease make sure you are authenticated if you are trying to access a private resource or a resource requiring consent."
          ]
        }
      ],
      "source": [
        "paligemma = keras_hub.models.PaliGemmaCausalLM.from_preset(\"kaggle://keras/paligemma2/keras/pali_gemma2_pt_3b_224\")\n",
        "paligemma.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBsWvKEvoGMe"
      },
      "source": [
        "## Create utility methods\n",
        "\n",
        "To help you generate responses from your model, create two utility methods:\n",
        "\n",
        "*   **`crop_and_resize`:** Helper method for `read_img`. This method crops and resizes the image to the passed in size so that the final image is resized without skewing the proportions of the image.\n",
        "*   **`read_img`:** Helper method for `read_img_from_url`. This method is what actually opens the image, resizes it so that it fits in the model's constraints, and puts it into an array that can be interpreted by the model.\n",
        "*   **`read_img_from_url`:** Takes in an image via a valid URL. You need this method to pass the image to the model.\n",
        "\n",
        "You'll use `read_img_from_url` in the next step of this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6_XQjhpvXiG"
      },
      "outputs": [],
      "source": [
        "def crop_and_resize(image, target_size):\n",
        "    width, height = image.size\n",
        "    source_size = min(image.size)\n",
        "    left = width // 2 - source_size // 2\n",
        "    top = height // 2 - source_size // 2\n",
        "    right, bottom = left + source_size, top + source_size\n",
        "    return image.resize(target_size, box=(left, top, right, bottom))\n",
        "\n",
        "def read_image(url, target_size):\n",
        "    contents = io.BytesIO(requests.get(url).content)\n",
        "    image = PIL.Image.open(contents)\n",
        "    image = crop_and_resize(image, target_size)\n",
        "    image = np.array(image)\n",
        "    # Remove alpha channel if necessary.\n",
        "    if image.shape[2] == 4:\n",
        "        image = image[:, :, :3]\n",
        "    return image\n",
        "\n",
        "def parse_bbox_and_labels(detokenized_output: str):\n",
        "  matches = re.finditer(\n",
        "      '<loc(?P<y0>\\d\\d\\d\\d)><loc(?P<x0>\\d\\d\\d\\d)><loc(?P<y1>\\d\\d\\d\\d)><loc(?P<x1>\\d\\d\\d\\d)>'\n",
        "      ' (?P<label>.+?)( ;|$)',\n",
        "      detokenized_output,\n",
        "  )\n",
        "  labels, boxes = [], []\n",
        "  fmt = lambda x: float(x) / 1024.0\n",
        "  for m in matches:\n",
        "    d = m.groupdict()\n",
        "    boxes.append([fmt(d['y0']), fmt(d['x0']), fmt(d['y1']), fmt(d['x1'])])\n",
        "    labels.append(d['label'])\n",
        "  return np.array(boxes), np.array(labels)\n",
        "\n",
        "def display_boxes(image, boxes, labels, target_image_size):\n",
        "  h, l = target_size\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.imshow(image)\n",
        "  for i in range(boxes.shape[0]):\n",
        "      y, x, y2, x2 = (boxes[i]*h)\n",
        "      width = x2 - x\n",
        "      height = y2 - y\n",
        "      # Create a Rectangle patch\n",
        "      rect = patches.Rectangle((x, y),\n",
        "                               width,\n",
        "                               height,\n",
        "                               linewidth=1,\n",
        "                               edgecolor='r',\n",
        "                               facecolor='none')\n",
        "      # Add label\n",
        "      plt.text(x, y, labels[i], color='red', fontsize=12)\n",
        "      # Add the patch to the Axes\n",
        "      ax.add_patch(rect)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "def display_segment_output(image, bounding_box, segment_mask, target_image_size):\n",
        "    # Initialize a full mask with the target size\n",
        "    full_mask = np.zeros(target_image_size, dtype=np.uint8)\n",
        "    target_width, target_height = target_image_size\n",
        "\n",
        "    for bbox, mask in zip(bounding_box, segment_mask):\n",
        "        y1, x1, y2, x2 = bbox\n",
        "        x1 = int(x1 * target_width)\n",
        "        y1 = int(y1 * target_height)\n",
        "        x2 = int(x2 * target_width)\n",
        "        y2 = int(y2 * target_height)\n",
        "\n",
        "        # Ensure mask is 2D before converting to Image\n",
        "        if mask.ndim == 3:\n",
        "            mask = mask.squeeze(axis=-1)\n",
        "        mask = Image.fromarray(mask)\n",
        "        mask = mask.resize((x2 - x1, y2 - y1), resample=Image.NEAREST)\n",
        "        mask = np.array(mask)\n",
        "        binary_mask = (mask > 0.5).astype(np.uint8)\n",
        "\n",
        "\n",
        "        # Place the binary mask onto the full mask\n",
        "        full_mask[y1:y2, x1:x2] = np.maximum(full_mask[y1:y2, x1:x2], binary_mask)\n",
        "    cmap = plt.get_cmap('jet')\n",
        "    colored_mask = cmap(full_mask / 1.0)\n",
        "    colored_mask = (colored_mask[:, :, :3] * 255).astype(np.uint8)\n",
        "    if isinstance(image, Image.Image):\n",
        "        image = np.array(image)\n",
        "    blended_image = image.copy()\n",
        "    mask_indices = full_mask > 0\n",
        "    alpha = 0.5\n",
        "\n",
        "    for c in range(3):\n",
        "        blended_image[:, :, c] = np.where(mask_indices,\n",
        "                                          (1 - alpha) * image[:, :, c] + alpha * colored_mask[:, :, c],\n",
        "                                          image[:, :, c])\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(blended_image)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeVUHA_zP8ZF"
      },
      "source": [
        "## Generate output\n",
        "\n",
        "After loading the model and creating utility methods, you can prompt the model with image and text data to generate a responses. PaliGemma models are trained with specific prompt syntax for specific tasks, such as `answer`, `caption`, and `detect`. For more information about PaliGemma prompt task syntax, see [PaliGemma prompt and system instructions](https://ai.google.dev/gemma/docs/paligemma/prompt-system-instructions##prompt_task_syntax).\n",
        "\n",
        "Prepare an image for use in a generation prompt by using the following code to load a test image into an object:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtPeUkGJFvXS"
      },
      "outputs": [],
      "source": [
        "target_size = (224, 224)\n",
        "image_url = 'https://storage.googleapis.com/keras-cv/models/paligemma/cow_beach_1.png'\n",
        "cow_image = read_image(image_url, target_size)\n",
        "matplotlib.pyplot.imshow(cow_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3FE63iMqb2G"
      },
      "source": [
        "### Answer in a specific language\n",
        "\n",
        "The following example code shows how to prompt the PaliGemma model for information about an object appearing in a provided image. This example uses the `answer {lang}` syntax and shows additional questions in other languages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQVmhpr6qdNH"
      },
      "outputs": [],
      "source": [
        "prompt = 'answer en where is the cow standing?\\n'\n",
        "# prompt = 'svar no hvor stÃ¥r kuen?\\n'\n",
        "# prompt = 'answer fr quelle couleur est le ciel?\\n'\n",
        "# prompt = 'responda pt qual a cor do animal?\\n'\n",
        "\n",
        "output = paligemma.generate(\n",
        "    inputs={\n",
        "        \"images\": cow_image,\n",
        "        \"prompts\": prompt,\n",
        "    }\n",
        ")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMPv8tfISvif"
      },
      "source": [
        "Note: Prompts that use PaliGemma prompt command syntax must end with an \"`\\n`\" character."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUgPcUGDpsdx"
      },
      "source": [
        "### Use `detect` prompt\n",
        "\n",
        "The following example code uses the `detect` prompt syntax to locate an object in the provided image. The code uses the previously defined `parse_bbox_and_labels()` and `display_boxes()` functions to interpret the model output and display the generated bounding boxes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noRIZtqnpzNn"
      },
      "outputs": [],
      "source": [
        "prompt = 'detect cow\\n'\n",
        "output = paligemma.generate(\n",
        "    inputs={\n",
        "        \"images\": cow_image,\n",
        "        \"prompts\": prompt,\n",
        "    }\n",
        ")\n",
        "boxes, labels = parse_bbox_and_labels(output)\n",
        "display_boxes(cow_image, boxes, labels, target_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TET0Bz10mzxD"
      },
      "source": [
        "### Use `segment` prompt\n",
        "\n",
        "The following example code uses the `segment` prompt syntax to locate the area of an image occupied by an object. It uses the Google `big_vision` library to interpret the model output and generate a mask for the segmented object.\n",
        "\n",
        "Before getting started, install the `big_vision` library and its dependencies, as shown in this code example:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuxyIMAvsM4B"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# TPUs with\n",
        "if \"COLAB_TPU_ADDR\" in os.environ:\n",
        "  raise \"It seems you are using Colab with remote TPUs which is not supported.\"\n",
        "\n",
        "# Fetch big_vision repository if python doesn't know about it and install\n",
        "# dependencies needed for this notebook.\n",
        "if not os.path.exists(\"big_vision_repo\"):\n",
        "  !git clone --quiet --branch=main --depth=1 \\\n",
        "     https://github.com/google-research/big_vision big_vision_repo\n",
        "\n",
        "# Append big_vision code to python import path\n",
        "if \"big_vision_repo\" not in sys.path:\n",
        "  sys.path.append(\"big_vision_repo\")\n",
        "\n",
        "\n",
        "# Install missing dependencies. Assume jax~=0.4.25 with GPU available.\n",
        "!pip3 install -q \"overrides\" \"ml_collections\" \"einops~=0.7\" \"sentencepiece\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18S4uHWqutps"
      },
      "source": [
        "For this segmentation example, load and prepare a different image that includes a cat."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Al6NedG4uNhp"
      },
      "outputs": [],
      "source": [
        "cat = read_image('https://big-vision-paligemma.hf.space/file=examples/barsik.jpg', target_size)\n",
        "matplotlib.pyplot.imshow(cat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRJYikeXu1As"
      },
      "source": [
        "Here is a function to help parse the segment output from PaliGemma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ryCMfGVuxyd"
      },
      "outputs": [],
      "source": [
        "import  big_vision.evaluators.proj.paligemma.transfers.segmentation as segeval\n",
        "reconstruct_masks = segeval.get_reconstruct_masks('oi')\n",
        "def parse_segments(detokenized_output: str) -> tuple[np.ndarray, np.ndarray]:\n",
        "  matches = re.finditer(\n",
        "      '<loc(?P<y0>\\d\\d\\d\\d)><loc(?P<x0>\\d\\d\\d\\d)><loc(?P<y1>\\d\\d\\d\\d)><loc(?P<x1>\\d\\d\\d\\d)>'\n",
        "      + ''.join(f'<seg(?P<s{i}>\\d\\d\\d)>' for i in range(16)),\n",
        "      detokenized_output,\n",
        "  )\n",
        "  boxes, segs = [], []\n",
        "  fmt_box = lambda x: float(x) / 1024.0\n",
        "  for m in matches:\n",
        "    d = m.groupdict()\n",
        "    boxes.append([fmt_box(d['y0']), fmt_box(d['x0']), fmt_box(d['y1']), fmt_box(d['x1'])])\n",
        "    segs.append([int(d[f's{i}']) for i in range(16)])\n",
        "  return np.array(boxes), np.array(reconstruct_masks(np.array(segs)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QITD66qJvCTO"
      },
      "source": [
        "Query PaliGemma to segment the cat in the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fB7to-J4u5zY"
      },
      "outputs": [],
      "source": [
        "prompt = 'segment cat\\n'\n",
        "output = paligemma.generate(\n",
        "    inputs={\n",
        "        \"images\": cat,\n",
        "        \"prompts\": prompt,\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZeu6-bovFvz"
      },
      "source": [
        "Visualize the generated mask from PaliGemma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcjOvoPbvAI-"
      },
      "outputs": [],
      "source": [
        "bboxes, seg_masks = parse_segments(output)\n",
        "display_segment_output(cat, bboxes, seg_masks, target_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI9YAgLuGyAb"
      },
      "source": [
        "### Batch prompts\n",
        "\n",
        "You can provide more than one prompt command within a single prompt as a batch of instructions. The following example demonstrates how to structure your prompt text to provide multiple instructions.\n",
        "\n",
        "Important: Each prompt command must end with an \"\\n\" character, as shown."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZle4sJP6YwB"
      },
      "outputs": [],
      "source": [
        "prompts = [\n",
        "    'answer en where is the cow standing?\\n',\n",
        "    'answer en what color is the cow?\\n',\n",
        "    'describe en\\n',\n",
        "    'detect cow\\n',\n",
        "    'segment cow\\n',\n",
        "]\n",
        "images = [cow_image, cow_image, cow_image, cow_image, cow_image]\n",
        "outputs = paligemma.generate(\n",
        "    inputs={\n",
        "        \"images\": images,\n",
        "        \"prompts\": prompts,\n",
        "    }\n",
        ")\n",
        "for output in outputs:\n",
        "    print(output)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "inference-with-keras.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}